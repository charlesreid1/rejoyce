{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing Ulysses with NLTK: Lestrygonians (Ch. 8)\n",
    "\n",
    "## Part II: Sentences and Phrases\n",
    "\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "\n",
    "### Table of Contents\n",
    "* [Introduction](#intro)\n",
    "* Sentences:\n",
    " * [Tokenizing Sentences](#tokenizing_sentences)\n",
    " \n",
    "<br />\n",
    "<br />\n",
    "<br />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"intro\"></a>\n",
    "## Introduction\n",
    "\n",
    "In Part I, we applied NLTK to James Joyce's _Ulysses_ and found some interesting features of Chapter 8, Lestrygonians. We started by analyzing characters and letter frequencies, and then moved on to words. In this notebook, we'll be looking at phrases. \n",
    "\n",
    "In particular, we'll try and improve the part of speech tagger by looking at the text at the phrase level, and we'll also apply some chunking algorithms to the text to chunk words into phrases based on their parts of speech.\n",
    "\n",
    "Let's start by importing our libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# In case we want to plot something:\n",
    "%matplotlib inline \n",
    "\n",
    "from __future__ import division\n",
    "import nltk, re\n",
    "\n",
    "# The io module makes unicode easier to deal with\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'unicode'>\n"
     ]
    }
   ],
   "source": [
    "file_contents = io.open('txt/08lestrygonians.txt','r').read()\n",
    "print type(file_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1979\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the chapter using the Punkt Tokenizer:\n",
    "sentences = nltk.sent_tokenize(file_contents)\n",
    "print len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'Pineapple rock, lemon platt, butter scotch.', u'A sugarsticky girl\\nshovelling scoopfuls of creams for a christian brother.', u'Some school\\ntreat.', u'Bad for their tummies.', u'Lozenge and comfit manufacturer to His\\nMajesty the King.', u'God.', u'Save.', u'Our.', u'Sitting on his throne sucking red\\njujubes white.', u'A sombre Y.M.C.A.']\n"
     ]
    }
   ],
   "source": [
    "print sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
